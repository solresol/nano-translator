{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import collections\n",
    "import scipy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pandas.read_excel(\"LibreOffice_Translations_sfx2messages_Tok Pisin.xlsx\", na_values='',\n",
    "                         dtype={'English': object, 'Tok Pisin': object})\n",
    "texts = texts[['English', 'Tok Pisin']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts.English = texts.English.map(str).str.replace('~','').str.replace('_','').str.upper()\n",
    "texts = texts[texts.English != 'SAVE'].copy()\n",
    "texts['Tok Pisin'] = texts['Tok Pisin'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_locations = set(texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocabulary = collections.defaultdict(list)\n",
    "for loc,message in zip(texts.index, texts.English):\n",
    "    for word in nltk.word_tokenize(message):\n",
    "        english_vocabulary[word].append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def everygram_generator(sequence, min_tokens=1, max_tokens=None):\n",
    "    sequence = list(sequence)\n",
    "    sequence_length = len(sequence)\n",
    "    if max_tokens is None:\n",
    "        max_tokens = len(sequence)\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(min_tokens, max_tokens+1):\n",
    "            if i+j < sequence_length:\n",
    "                yield tuple(sequence[i:i+j])\n",
    "\n",
    "def possible_translation_phrases(english_word):\n",
    "    locations = english_vocabulary[english_word]\n",
    "    for location in locations:\n",
    "        tokens_of_translation = nltk.word_tokenize(texts.loc[location]['Tok Pisin'])\n",
    "        for ngram in everygram_generator(tokens_of_translation, max_tokens=4):\n",
    "            yield ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokpisin_vocabulary = collections.defaultdict(list)\n",
    "for loc,message in zip(texts.index, texts['Tok Pisin']):\n",
    "    for word in everygram_generator(nltk.word_tokenize(message),max_tokens=4):\n",
    "        tokpisin_vocabulary[word].append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(everygram_generator([\"The\", \"quick\", \"brown\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(possible_translation_phrases(\"SAVE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_translation(english_word):\n",
    "    english_word = english_word.upper()\n",
    "    english_locations = set(english_vocabulary[english_word])\n",
    "    possible_tokpisin_phrases = possible_translation_phrases(english_word)\n",
    "    lowest_probability = 1.0\n",
    "    lowest_probability_phrase = None\n",
    "    for possible_phrase in set(possible_tokpisin_phrases):\n",
    "        tokpisin_locations = set(tokpisin_vocabulary[possible_phrase])\n",
    "        together = english_locations.intersection(tokpisin_locations)\n",
    "        probability = scipy.stats.binom_test(len(together),\n",
    "                                            len(english_locations),\n",
    "                                            len(tokpisin_locations) / len(all_locations),\n",
    "                                            alternative='greater')\n",
    "        bonferroni_corrected = (1 - ((1 - probability) ** len(possible_phrase)))\n",
    "        if bonferroni_corrected < lowest_probability:\n",
    "            lowest_probability = bonferroni_corrected\n",
    "            lowest_probability_phrase = possible_phrase\n",
    "    return (lowest_probability, lowest_probability_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_translation(\"SAVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "extra_vocab = []\n",
    "for word in english_vocabulary:\n",
    "    if word in set(texts.English):\n",
    "        # no need to figure it out, we've got a translation\n",
    "        continue\n",
    "    confidence, translation = guess_translation(word)\n",
    "    if translation is None:\n",
    "        continue\n",
    "    extra_vocab.append({'English': word, 'Tok Pisin': \" \".join(translation), 'confidence': confidence})\n",
    "extra_vocab = pandas.DataFrame.from_records(extra_vocab).sort_values('confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_vocab.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_vocab.to_excel(\"derived-tokpisin-vocab.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-conditions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
